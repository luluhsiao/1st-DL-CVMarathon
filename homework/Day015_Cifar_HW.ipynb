{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "Day015_Cifar_HW (2).ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6LYT8MbmhXz"
      },
      "source": [
        "## 『本次練習內容』\n",
        "#### 運用這幾天所學觀念搭建一個CNN分類器"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_rfXpC_mhX5"
      },
      "source": [
        "## 『本次練習目的』\n",
        "  #### 熟悉CNN分類器搭建步驟與原理\n",
        "  #### 學員們可以嘗試不同搭法，如使用不同的Maxpooling層，用GlobalAveragePooling取代Flatten等等"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZUd0uyymhX5"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Convolution2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import GlobalAveragePooling2D\n",
        "from keras.datasets import cifar10\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import OneHotEncoder\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4PgvaGzDmhX6",
        "outputId": "3b866538-f0a0-4a24-8359-7a003aba70fc"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "print(x_train.shape) #(50000, 32, 32, 3)\n",
        "\n",
        "## Normalize Data\n",
        "def normalize(X_train,X_test):\n",
        "        mean = np.mean(X_train,axis=(0,1,2,3))\n",
        "        std = np.std(X_train, axis=(0, 1, 2, 3))\n",
        "        X_train = (X_train-mean)/(std+1e-7)\n",
        "        X_test = (X_test-mean)/(std+1e-7) \n",
        "        return X_train, X_test,mean,std\n",
        "    \n",
        "    \n",
        "## Normalize Training and Testset    \n",
        "x_train, x_test,mean_train,std_train = normalize(x_train, x_test) "
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 2s 0us/step\n",
            "(50000, 32, 32, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fC2SDFuqmhX7"
      },
      "source": [
        "## OneHot Label 由(None, 1)-(None, 10)\n",
        "## ex. label=2,變成[0,0,1,0,0,0,0,0,0,0]\n",
        "one_hot=OneHotEncoder()\n",
        "y_train=one_hot.fit_transform(y_train).toarray()\n",
        "y_test=one_hot.transform(y_test).toarray()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4L2fkexqmhX7",
        "outputId": "e3e63546-a696-41a4-d222-9085264a7f0b"
      },
      "source": [
        "classifier=Sequential()\n",
        "\n",
        "#卷積組合\n",
        "input_shape = (32, 32, 3)\n",
        "classifier.add(Convolution2D(32, kernel_size=(3, 3), padding='same',input_shape=input_shape,activation='relu'))#32,3,3,input_shape=(32,32,3),activation='relu''\n",
        "classifier.add(BatchNormalization())\n",
        "\n",
        "#卷積組合\n",
        "classifier.add(Convolution2D(64, kernel_size=(3, 3), padding='same', activation='relu'))\n",
        "classifier.add(BatchNormalization())\n",
        "\n",
        "#卷積組合\n",
        "classifier.add(Convolution2D(128, kernel_size=(3, 3), padding='same', activation='relu'))\n",
        "classifier.add(BatchNormalization())\n",
        "\n",
        "\n",
        "'''自己決定MaxPooling2D放在哪裡'''\n",
        "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "#卷積組合\n",
        "classifier.add(Convolution2D(128, kernel_size=(3, 3), padding='same', activation='relu'))\n",
        "classifier.add(BatchNormalization())\n",
        "\n",
        "\n",
        "#flatten\n",
        "#classifier.add(Flatten())\n",
        "classifier.add(GlobalAveragePooling2D())\n",
        "\n",
        "#FC\n",
        "classifier.add(Dense(100,activation='relu')) #output_dim=100,activation=relu\n",
        "\n",
        "#輸出\n",
        "classifier.add(Dense(10,activation='softmax'))\n",
        "\n",
        "#超過兩個就要選categorical_crossentrophy\n",
        "classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "classifier.fit(x_train,y_train,batch_size=100,epochs=100)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "500/500 [==============================] - 45s 23ms/step - loss: 1.5863 - accuracy: 0.4209\n",
            "Epoch 2/100\n",
            "500/500 [==============================] - 12s 23ms/step - loss: 1.0241 - accuracy: 0.6348\n",
            "Epoch 3/100\n",
            "500/500 [==============================] - 12s 23ms/step - loss: 0.8128 - accuracy: 0.7128\n",
            "Epoch 4/100\n",
            "500/500 [==============================] - 12s 24ms/step - loss: 0.6691 - accuracy: 0.7667\n",
            "Epoch 5/100\n",
            "500/500 [==============================] - 12s 24ms/step - loss: 0.5627 - accuracy: 0.8046\n",
            "Epoch 6/100\n",
            "500/500 [==============================] - 12s 24ms/step - loss: 0.4808 - accuracy: 0.8348\n",
            "Epoch 7/100\n",
            "500/500 [==============================] - 12s 24ms/step - loss: 0.4168 - accuracy: 0.8567\n",
            "Epoch 8/100\n",
            "500/500 [==============================] - 12s 24ms/step - loss: 0.3502 - accuracy: 0.8795\n",
            "Epoch 9/100\n",
            "500/500 [==============================] - 12s 24ms/step - loss: 0.2980 - accuracy: 0.8988\n",
            "Epoch 10/100\n",
            "500/500 [==============================] - 12s 24ms/step - loss: 0.2506 - accuracy: 0.9153\n",
            "Epoch 11/100\n",
            "500/500 [==============================] - 12s 24ms/step - loss: 0.2151 - accuracy: 0.9275\n",
            "Epoch 12/100\n",
            "500/500 [==============================] - 12s 24ms/step - loss: 0.1711 - accuracy: 0.9431\n",
            "Epoch 13/100\n",
            "500/500 [==============================] - 12s 24ms/step - loss: 0.1492 - accuracy: 0.9508\n",
            "Epoch 14/100\n",
            "500/500 [==============================] - 12s 24ms/step - loss: 0.1280 - accuracy: 0.9568\n",
            "Epoch 15/100\n",
            "500/500 [==============================] - 12s 24ms/step - loss: 0.1072 - accuracy: 0.9651\n",
            "Epoch 16/100\n",
            "500/500 [==============================] - 12s 24ms/step - loss: 0.0944 - accuracy: 0.9688\n",
            "Epoch 17/100\n",
            "500/500 [==============================] - 12s 24ms/step - loss: 0.0775 - accuracy: 0.9758\n",
            "Epoch 18/100\n",
            "500/500 [==============================] - 12s 24ms/step - loss: 0.0840 - accuracy: 0.9719\n",
            "Epoch 19/100\n",
            "500/500 [==============================] - 12s 24ms/step - loss: 0.0725 - accuracy: 0.9748\n",
            "Epoch 20/100\n",
            "500/500 [==============================] - 12s 24ms/step - loss: 0.0707 - accuracy: 0.9757\n",
            "Epoch 21/100\n",
            "500/500 [==============================] - 12s 24ms/step - loss: 0.0538 - accuracy: 0.9829\n",
            "Epoch 22/100\n",
            "500/500 [==============================] - 12s 24ms/step - loss: 0.0607 - accuracy: 0.9782\n",
            "Epoch 23/100\n",
            "500/500 [==============================] - 12s 24ms/step - loss: 0.0525 - accuracy: 0.9824\n",
            "Epoch 24/100\n",
            "500/500 [==============================] - 12s 24ms/step - loss: 0.0498 - accuracy: 0.9827\n",
            "Epoch 25/100\n",
            "500/500 [==============================] - 12s 24ms/step - loss: 0.0484 - accuracy: 0.9838\n",
            "Epoch 26/100\n",
            "500/500 [==============================] - 12s 24ms/step - loss: 0.0469 - accuracy: 0.9839\n",
            "Epoch 27/100\n",
            "500/500 [==============================] - 12s 24ms/step - loss: 0.0478 - accuracy: 0.9837\n",
            "Epoch 28/100\n",
            "500/500 [==============================] - 12s 24ms/step - loss: 0.0433 - accuracy: 0.9856\n",
            "Epoch 29/100\n",
            "500/500 [==============================] - 12s 24ms/step - loss: 0.0435 - accuracy: 0.9843\n",
            "Epoch 30/100\n",
            "500/500 [==============================] - 12s 24ms/step - loss: 0.0442 - accuracy: 0.9852\n",
            "Epoch 31/100\n",
            "500/500 [==============================] - 12s 24ms/step - loss: 0.0349 - accuracy: 0.9881\n",
            "Epoch 32/100\n",
            "500/500 [==============================] - 12s 24ms/step - loss: 0.0394 - accuracy: 0.9870\n",
            "Epoch 33/100\n",
            "500/500 [==============================] - 12s 24ms/step - loss: 0.0391 - accuracy: 0.9872\n",
            "Epoch 34/100\n",
            "500/500 [==============================] - 12s 24ms/step - loss: 0.0318 - accuracy: 0.9892\n",
            "Epoch 35/100\n",
            "500/500 [==============================] - 12s 24ms/step - loss: 0.0350 - accuracy: 0.9883\n",
            "Epoch 36/100\n",
            "500/500 [==============================] - 12s 24ms/step - loss: 0.0457 - accuracy: 0.9836\n",
            "Epoch 37/100\n",
            "500/500 [==============================] - 12s 24ms/step - loss: 0.0313 - accuracy: 0.9891\n",
            "Epoch 38/100\n",
            "500/500 [==============================] - 12s 24ms/step - loss: 0.0266 - accuracy: 0.9912\n",
            "Epoch 39/100\n",
            "500/500 [==============================] - 12s 24ms/step - loss: 0.0348 - accuracy: 0.9872\n",
            "Epoch 40/100\n",
            "500/500 [==============================] - 12s 24ms/step - loss: 0.0342 - accuracy: 0.9881\n",
            "Epoch 41/100\n",
            "500/500 [==============================] - 12s 24ms/step - loss: 0.0280 - accuracy: 0.9904\n",
            "Epoch 42/100\n",
            "500/500 [==============================] - 12s 24ms/step - loss: 0.0322 - accuracy: 0.9885\n",
            "Epoch 43/100\n",
            "500/500 [==============================] - 12s 24ms/step - loss: 0.0305 - accuracy: 0.9896\n",
            "Epoch 44/100\n",
            "500/500 [==============================] - 12s 24ms/step - loss: 0.0302 - accuracy: 0.9892\n",
            "Epoch 45/100\n",
            "500/500 [==============================] - 12s 24ms/step - loss: 0.0273 - accuracy: 0.9907\n",
            "Epoch 46/100\n",
            "500/500 [==============================] - 12s 24ms/step - loss: 0.0246 - accuracy: 0.9916\n",
            "Epoch 47/100\n",
            "500/500 [==============================] - 12s 24ms/step - loss: 0.0278 - accuracy: 0.9906\n",
            "Epoch 48/100\n",
            "500/500 [==============================] - 12s 24ms/step - loss: 0.0323 - accuracy: 0.9880\n",
            "Epoch 49/100\n",
            "500/500 [==============================] - 12s 24ms/step - loss: 0.0287 - accuracy: 0.9899\n",
            "Epoch 50/100\n",
            "500/500 [==============================] - 12s 24ms/step - loss: 0.0195 - accuracy: 0.9936\n",
            "Epoch 51/100\n",
            "500/500 [==============================] - 12s 24ms/step - loss: 0.0185 - accuracy: 0.9944\n",
            "Epoch 52/100\n",
            "500/500 [==============================] - 12s 24ms/step - loss: 0.0318 - accuracy: 0.9884\n",
            "Epoch 53/100\n",
            "500/500 [==============================] - 12s 24ms/step - loss: 0.0208 - accuracy: 0.9932\n",
            "Epoch 54/100\n",
            "500/500 [==============================] - 12s 24ms/step - loss: 0.0222 - accuracy: 0.9919\n",
            "Epoch 55/100\n",
            "500/500 [==============================] - 12s 24ms/step - loss: 0.0282 - accuracy: 0.9898\n",
            "Epoch 56/100\n",
            "500/500 [==============================] - 12s 24ms/step - loss: 0.0236 - accuracy: 0.9915\n",
            "Epoch 57/100\n",
            "500/500 [==============================] - 12s 24ms/step - loss: 0.0238 - accuracy: 0.9917\n",
            "Epoch 58/100\n",
            "500/500 [==============================] - 12s 24ms/step - loss: 0.0220 - accuracy: 0.9924\n",
            "Epoch 59/100\n",
            "500/500 [==============================] - 12s 24ms/step - loss: 0.0230 - accuracy: 0.9921\n",
            "Epoch 60/100\n",
            "500/500 [==============================] - 12s 24ms/step - loss: 0.0189 - accuracy: 0.9928\n",
            "Epoch 61/100\n",
            "500/500 [==============================] - 12s 24ms/step - loss: 0.0171 - accuracy: 0.9943\n",
            "Epoch 62/100\n",
            "500/500 [==============================] - 12s 24ms/step - loss: 0.0264 - accuracy: 0.9909\n",
            "Epoch 63/100\n",
            "500/500 [==============================] - 12s 24ms/step - loss: 0.0165 - accuracy: 0.9945\n",
            "Epoch 64/100\n",
            "500/500 [==============================] - 12s 24ms/step - loss: 0.0237 - accuracy: 0.9909\n",
            "Epoch 65/100\n",
            "500/500 [==============================] - 12s 24ms/step - loss: 0.0197 - accuracy: 0.9932\n",
            "Epoch 66/100\n",
            "500/500 [==============================] - 12s 24ms/step - loss: 0.0243 - accuracy: 0.9911\n",
            "Epoch 67/100\n",
            "500/500 [==============================] - 12s 24ms/step - loss: 0.0165 - accuracy: 0.9945\n",
            "Epoch 68/100\n",
            "500/500 [==============================] - 12s 24ms/step - loss: 0.0128 - accuracy: 0.9956\n",
            "Epoch 69/100\n",
            "500/500 [==============================] - 12s 24ms/step - loss: 0.0254 - accuracy: 0.9907\n",
            "Epoch 70/100\n",
            "500/500 [==============================] - 12s 24ms/step - loss: 0.0188 - accuracy: 0.9935\n",
            "Epoch 71/100\n",
            "500/500 [==============================] - 12s 24ms/step - loss: 0.0192 - accuracy: 0.9928\n",
            "Epoch 72/100\n",
            "500/500 [==============================] - 12s 24ms/step - loss: 0.0179 - accuracy: 0.9935\n",
            "Epoch 73/100\n",
            "500/500 [==============================] - 12s 24ms/step - loss: 0.0171 - accuracy: 0.9936\n",
            "Epoch 74/100\n",
            "500/500 [==============================] - 12s 24ms/step - loss: 0.0186 - accuracy: 0.9937\n",
            "Epoch 75/100\n",
            "500/500 [==============================] - 12s 24ms/step - loss: 0.0175 - accuracy: 0.9936\n",
            "Epoch 76/100\n",
            "500/500 [==============================] - 12s 24ms/step - loss: 0.0169 - accuracy: 0.9943\n",
            "Epoch 77/100\n",
            "500/500 [==============================] - 12s 24ms/step - loss: 0.0201 - accuracy: 0.9927\n",
            "Epoch 78/100\n",
            "500/500 [==============================] - 12s 24ms/step - loss: 0.0154 - accuracy: 0.9947\n",
            "Epoch 79/100\n",
            "500/500 [==============================] - 12s 24ms/step - loss: 0.0128 - accuracy: 0.9956\n",
            "Epoch 80/100\n",
            "500/500 [==============================] - 12s 24ms/step - loss: 0.0160 - accuracy: 0.9951\n",
            "Epoch 81/100\n",
            "500/500 [==============================] - 12s 24ms/step - loss: 0.0226 - accuracy: 0.9922\n",
            "Epoch 82/100\n",
            "500/500 [==============================] - 12s 24ms/step - loss: 0.0124 - accuracy: 0.9959\n",
            "Epoch 83/100\n",
            "500/500 [==============================] - 12s 24ms/step - loss: 0.0122 - accuracy: 0.9957\n",
            "Epoch 84/100\n",
            "500/500 [==============================] - 12s 24ms/step - loss: 0.0188 - accuracy: 0.9933\n",
            "Epoch 85/100\n",
            "500/500 [==============================] - 12s 24ms/step - loss: 0.0160 - accuracy: 0.9940\n",
            "Epoch 86/100\n",
            "500/500 [==============================] - 12s 24ms/step - loss: 0.0177 - accuracy: 0.9944\n",
            "Epoch 87/100\n",
            "500/500 [==============================] - 12s 24ms/step - loss: 0.0111 - accuracy: 0.9961\n",
            "Epoch 88/100\n",
            "500/500 [==============================] - 12s 24ms/step - loss: 0.0162 - accuracy: 0.9943\n",
            "Epoch 89/100\n",
            "500/500 [==============================] - 12s 24ms/step - loss: 0.0189 - accuracy: 0.9934\n",
            "Epoch 90/100\n",
            "500/500 [==============================] - 12s 24ms/step - loss: 0.0162 - accuracy: 0.9941\n",
            "Epoch 91/100\n",
            "500/500 [==============================] - 12s 24ms/step - loss: 0.0099 - accuracy: 0.9968\n",
            "Epoch 92/100\n",
            "500/500 [==============================] - 12s 24ms/step - loss: 0.0122 - accuracy: 0.9954\n",
            "Epoch 93/100\n",
            "500/500 [==============================] - 12s 24ms/step - loss: 0.0185 - accuracy: 0.9939\n",
            "Epoch 94/100\n",
            "500/500 [==============================] - 12s 24ms/step - loss: 0.0172 - accuracy: 0.9939\n",
            "Epoch 95/100\n",
            "500/500 [==============================] - 12s 24ms/step - loss: 0.0118 - accuracy: 0.9953\n",
            "Epoch 96/100\n",
            "500/500 [==============================] - 12s 24ms/step - loss: 0.0148 - accuracy: 0.9950\n",
            "Epoch 97/100\n",
            "500/500 [==============================] - 12s 24ms/step - loss: 0.0125 - accuracy: 0.9957\n",
            "Epoch 98/100\n",
            "500/500 [==============================] - 12s 24ms/step - loss: 0.0149 - accuracy: 0.9949\n",
            "Epoch 99/100\n",
            "500/500 [==============================] - 12s 24ms/step - loss: 0.0140 - accuracy: 0.9957\n",
            "Epoch 100/100\n",
            "500/500 [==============================] - 12s 24ms/step - loss: 0.0085 - accuracy: 0.9972\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f045b79ea10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Ejjjfn-BhiH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5a49725-18d4-427e-e075-d9c19b592547"
      },
      "source": [
        "#預測test data結果\n",
        "score = classifier.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 1.348757028579712\n",
            "Test accuracy: 0.805899977684021\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzVk5BxsmhX8"
      },
      "source": [
        "## 預測新圖片，輸入影像前處理要與訓練時相同\n",
        "#### ((X-mean)/(std+1e-7) ):這裡的mean跟std是訓練集的\n",
        "## 維度如下方示範"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84bb0on0mhX8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61507d98-981d-46ec-ff76-3a706de7c7be"
      },
      "source": [
        "input_example=(np.zeros(shape=(1,32,32,3))-mean_train)/(std_train+1e-7) \n",
        "classifier.predict(input_example)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.0115324e-03, 1.8121418e-05, 1.0442817e-01, 1.2968809e-02,\n",
              "        8.7652749e-01, 2.5466858e-07, 9.9008309e-04, 7.9634656e-06,\n",
              "        4.0475712e-03, 9.3497931e-08]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "likpL07NmhX8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}